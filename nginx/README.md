# Nginx Reverse Proxy & Load Balancer Configuration

This directory contains the Nginx configuration for reverse proxy, load balancing, SSL/TLS, rate limiting, and health checks for the Opareta services.

## Features

- **Reverse Proxy**: Routes requests to auth and payments services with proper header forwarding
- **Load Balancing**: Distributes traffic across scaled instances using Nginx upstream blocks
- **SSL/TLS**: Self-signed certificate for HTTPS (acceptable for development)
- **Rate Limiting**: 100 requests per minute per IP address for API endpoints
- **Health Checks**: Dedicated endpoints for service health monitoring (available on HTTP and HTTPS)
- **Access Logging**: Comprehensive logging with upstream timing metrics
- **Monitoring**: Nginx status endpoint for Prometheus metrics collection

## Directory Structure

```
nginx/
├── nginx.conf              # Main Nginx configuration
├── conf.d/
│   ├── upstream.conf       # Upstream configuration for load balancing
│   └── opareta.conf        # Site-specific configuration
├── ssl/
│   ├── opareta.crt         # SSL certificate
│   └── opareta.key         # SSL private key
├── logs/                   # Nginx access and error logs
├── Dockerfile              # Nginx container definition
├── generate-ssl.sh         # Script to generate self-signed certificate
└── README.md               # This file
```

## Configuration Details

### Load Balancing

- **Upstream Configuration**: Uses Nginx upstream blocks defined in `conf.d/upstream.conf`
- **Round-Robin Load Balancing**: Nginx distributes requests across all scaled instances
- **Auth Service**: Load balanced via `auth_backend` upstream block
- **Payments Service**: Load balanced via `payments_backend` upstream block
- **Scaling**: Use `docker-compose up --scale auth=2 --scale payments=2` to run 2 instances
- **Health Checks**: Automatic failover with `max_fails=3` and `fail_timeout=30s`
- **Keepalive**: Connection pooling with `keepalive 32` for better performance
- **DNS Resolution**: Uses Docker's internal DNS resolver (127.0.0.11) for service discovery

### Rate Limiting

- **API Endpoints**: 100 requests per minute per IP (with burst of 20)
- **Health Check Endpoints**: 10 requests per second per IP (with burst of 20)
- **Response**: HTTP 429 (Too Many Requests) when limit exceeded

### SSL/TLS

- **Protocols**: TLSv1.2 and TLSv1.3
- **Certificate**: Self-signed (generated by `generate-ssl.sh`)
- **Ports**: HTTP (80) redirects to HTTPS (443), except for health check endpoints
- **HTTP/2**: Enabled on HTTPS server for improved performance
- **Session Caching**: SSL session cache (10m) and timeout (10m) for better performance

### Proxy Configuration

- **Timeouts**: 60s for connect, send, and read operations (5s for health checks)
- **Buffering**: Enabled with optimized buffer sizes (4k buffer, 8 buffers, 8k busy buffer)
- **Headers**: Proper forwarding of X-Real-IP, X-Forwarded-For, X-Forwarded-Proto, X-Forwarded-Host, X-Forwarded-Port

### Health Check Endpoints

- **Nginx Health**: `http://localhost/nginx-health` or `https://localhost/nginx-health`
- **Auth Service**: `http://localhost/auth/health` or `https://localhost/auth/health`
- **Payments Service**: `http://localhost/payments/health` or `https://localhost/payments/health`
- **Nginx Status** (for monitoring): `https://localhost/nginx_status` (restricted to internal networks)

### Service Routes

- **Auth Service**: `https://localhost/auth/*`
- **Payments Service**: `https://localhost/payments/*`

## Setup Instructions

1. **Generate SSL Certificate** (if not already generated):
   ```bash
   cd nginx
   ./generate-ssl.sh
   ```

2. **Start Services with Scaling** (2 instances of each service):
   ```bash
   docker-compose up -d --scale auth=2 --scale payments=2
   ```

   Or start normally (1 instance each):
   ```bash
   docker-compose up -d
   ```

   **Note**: Nginx upstream blocks automatically handle load balancing across scaled instances!

3. **Verify Nginx is Running**:
   ```bash
   curl http://localhost/nginx-health
   ```

4. **Test Health Checks**:
   ```bash
   curl http://localhost/auth/health
   curl http://localhost/payments/health
   ```

5. **Test HTTPS** (accept self-signed certificate):
   ```bash
   curl -k https://localhost/auth/health
   curl -k https://localhost/payments/health
   ```

6. **Scale Services Dynamically**:
   ```bash
   docker-compose up -d --scale auth=3 --scale payments=3
   ```
   Nginx will automatically distribute traffic across all instances - no reload needed!

## Logs

Access logs are stored in:
- `/var/log/nginx/access.log` - General access log
- `/var/log/nginx/opareta-access.log` - Site-specific access log
- `/var/log/nginx/health-access.log` - Health check access log
- `/var/log/nginx/error.log` - Error log
- `/var/log/nginx/opareta-error.log` - Site-specific error log

Logs are mounted to `./nginx/logs/` on the host.

## Security Headers

The following security headers are configured:
- `Strict-Transport-Security`: Enforces HTTPS
- `X-Frame-Options`: Prevents clickjacking
- `X-Content-Type-Options`: Prevents MIME type sniffing
- `X-XSS-Protection`: Enables XSS protection

## Monitoring Integration

- **Nginx Status Endpoint**: Available at `/nginx_status` for Prometheus scraping
- **Access Control**: Status endpoint is restricted to internal networks (127.0.0.1, 172.16.0.0/12, 10.0.0.0/8)
- **Metrics**: Nginx exporter scrapes the status endpoint and exposes metrics to Prometheus
- **Logging**: Enhanced log format includes upstream timing metrics (uct, uht, urt)

## Notes

- The self-signed certificate will show a browser warning. This is expected for development.
- For production, replace the self-signed certificate with a valid certificate from a CA.
- Rate limiting is applied per IP address.
- Health checks have their own rate limit (10 req/s) to prevent abuse while allowing monitoring.
- Load balancing uses Nginx upstream blocks with Docker DNS resolution for automatic service discovery.
- Health check endpoints are available on both HTTP (port 80) and HTTPS (port 443) for flexibility.
- The upstream configuration supports automatic failover when backend services become unhealthy.

